{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 64148,
          "databundleVersionId": 7669720,
          "sourceType": "competition"
        },
        {
          "sourceId": 7705679,
          "sourceType": "datasetVersion",
          "datasetId": 4498747
        },
        {
          "sourceId": 11382,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 8318
        }
      ],
      "dockerImageVersionId": 30674,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "RAG using Gemma, Langchain and ChromaDB",
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9b5655050e646a1965ca67153b051cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_23875ad0854541b28005bbbcd5d19af0"
          }
        },
        "998281fdc59a4cb6aef385b2bba34ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c3609392aeb4a80bab7c26b59de3934",
            "placeholder": "​",
            "style": "IPY_MODEL_4349a2106c954c84af57665cc8a7f7bf",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "e41cb1daf4e147b19270559776e7f4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_82c0e5be53844bd38dae8794248ba47b",
            "placeholder": "​",
            "style": "IPY_MODEL_b77ad5ae95f1492ead1745ca05587b9a",
            "value": ""
          }
        },
        "131d116af9dc48b0bf79d18abeff421a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_751e2035630a47c984176d3e029c27ef",
            "style": "IPY_MODEL_f0dc36cc34634fa780e7ddbd1fe764b7",
            "value": true
          }
        },
        "3ed7ad9432f449518300e140612f6880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_95a421a10f4d45b9aa4972e864e364d9",
            "style": "IPY_MODEL_c8066a2bd3994e319268a35c03a52023",
            "tooltip": ""
          }
        },
        "350c9fb2ba3f4d8fb93fdab50d307adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75420177c0ff40fdaf32f95c8c8884af",
            "placeholder": "​",
            "style": "IPY_MODEL_aef40100456544cd8caa4c88eb24607f",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "23875ad0854541b28005bbbcd5d19af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "1c3609392aeb4a80bab7c26b59de3934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4349a2106c954c84af57665cc8a7f7bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82c0e5be53844bd38dae8794248ba47b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b77ad5ae95f1492ead1745ca05587b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "751e2035630a47c984176d3e029c27ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0dc36cc34634fa780e7ddbd1fe764b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95a421a10f4d45b9aa4972e864e364d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8066a2bd3994e319268a35c03a52023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "75420177c0ff40fdaf32f95c8c8884af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef40100456544cd8caa4c88eb24607f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9009125d30564b749cc2415f370fb7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b03fce72364f9296f4e6fd9b408aad",
            "placeholder": "​",
            "style": "IPY_MODEL_35a737c7179e434a8ec71988b1d99523",
            "value": "Connecting..."
          }
        },
        "64b03fce72364f9296f4e6fd9b408aad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35a737c7179e434a8ec71988b1d99523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sahanave/found_it_using_gemma/blob/main/Found_it_using_Gemma%2C_Langchain_and_ChromaDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1>Retriving detected objects using Gemma</h1></center>\n",
        "<center><img src=\"https://res.infoq.com/news/2024/02/google-gemma-open-model/en/headerimage/generatedHeaderImage-1708977571481.jpg\" width=\"400\"></center>\n",
        "\n",
        "\n",
        "# Introduction\n",
        "\n",
        "This notebook demonstrates how to build a retrieval augmented generation (RAG) system using Gemma as a large language model (LLM), Langchain for tools to process input files, and ChromaDB as vector database.\n",
        "\n",
        "## What is RAG?\n",
        "\n",
        "Retriever augmented generation (RAG) is a system that improves the response generated by a LLM in two ways:\n",
        "- First, the information is retrieved from a dataset that is stored in vector database; the query is used to perform similarity search in the documents stored in the vector database.\n",
        "- Second, by restraining the context provided to the LLM to content that is similar with the initial query, stored in the vector database, we can reduce significantly (or even eliminate) LLM's halucinations, since the answer is provided from the context of the stored documents.\n",
        "\n",
        "An important advantage of this approach is that we do not need to fine-tune the LLM with our custom data; instead, the data is ingested (cleaned, transformed, chunked, and indexed in the vector database).\n",
        "\n",
        "## Procedure\n",
        "\n",
        "We create two classes:\n",
        "* AIAgent - An AI Agent that query Gemma LLM using a custom prompt that instruct Gemma to generate and answer (from the query) by refering to the context (as well provided); the answer to the AI Agent query function is then returned.\n",
        "* RAGSystem - initialized with the dataset with Data Science information, with an AIAgent object. In the init function of this class, we ingest the data from the dataset in the vector database. This class have as well a query member function. In this function we first perform similarity search with the query to the vector database. Then, we call the generate function of the ai agent object. Before returning the answer, we use a predefined template to compose the overal response from the question, answer and the context retrieved.\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "fRPL40GHSI-v"
      }
    },
    {
      "source": [
        "#Installing Paligemma packages\n",
        "!pip install -q -U accelerate bitsandbytes git+https://github.com/huggingface/transformers.git\n"
      ],
      "metadata": {
        "id": "EBaqFK8PSI-u",
        "outputId": "f0d5d14c-efe7-4ab4-a803-b9cea10235f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "EMKQiiFZFO2Y",
        "outputId": "24ebc4e9-66b4-4f77-e6f5-73aeb94f7e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "f9b5655050e646a1965ca67153b051cb",
            "998281fdc59a4cb6aef385b2bba34ee2",
            "e41cb1daf4e147b19270559776e7f4a3",
            "131d116af9dc48b0bf79d18abeff421a",
            "3ed7ad9432f449518300e140612f6880",
            "350c9fb2ba3f4d8fb93fdab50d307adb",
            "23875ad0854541b28005bbbcd5d19af0",
            "1c3609392aeb4a80bab7c26b59de3934",
            "4349a2106c954c84af57665cc8a7f7bf",
            "82c0e5be53844bd38dae8794248ba47b",
            "b77ad5ae95f1492ead1745ca05587b9a",
            "751e2035630a47c984176d3e029c27ef",
            "f0dc36cc34634fa780e7ddbd1fe764b7",
            "95a421a10f4d45b9aa4972e864e364d9",
            "c8066a2bd3994e319268a35c03a52023",
            "75420177c0ff40fdaf32f95c8c8884af",
            "aef40100456544cd8caa4c88eb24607f",
            "9009125d30564b749cc2415f370fb7b8",
            "64b03fce72364f9296f4e6fd9b408aad",
            "35a737c7179e434a8ec71988b1d99523"
          ]
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9b5655050e646a1965ca67153b051cb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Uby4zT11FcH5",
        "outputId": "dbfe37d5-ecce-4023-fbec-d25e6c49ef54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XUfrxQRME8eD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages instalation and configurations"
      ],
      "metadata": {
        "id": "hnBjNZcGSI-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install required libraries\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install accelerate\n",
        "!pip install -i https://pypi.org/simple/ bitsandbytes\n",
        "!pip install langchain\n",
        "!pip install sentence-transformers\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T20:42:33.256721Z",
          "iopub.execute_input": "2024-04-05T20:42:33.257323Z",
          "iopub.status.idle": "2024-04-05T20:44:58.804489Z",
          "shell.execute_reply.started": "2024-04-05T20:42:33.257291Z",
          "shell.execute_reply": "2024-04-05T20:44:58.803391Z"
        },
        "trusted": true,
        "id": "fZOo6JZrSI-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "from IPython.display import display, Markdown\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T20:44:58.806421Z",
          "iopub.execute_input": "2024-04-05T20:44:58.806721Z",
          "iopub.status.idle": "2024-04-05T20:45:04.553528Z",
          "shell.execute_reply.started": "2024-04-05T20:44:58.806697Z",
          "shell.execute_reply": "2024-04-05T20:45:04.55253Z"
        },
        "trusted": true,
        "id": "-jhgpVAESI-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Agent class"
      ],
      "metadata": {
        "id": "uO0GP-ReSI-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AIAgent:\n",
        "    \"\"\"\n",
        "    Gemma 2b-it assistant.\n",
        "    It uses Gemma transformers 2b-it/2.\n",
        "    \"\"\"\n",
        "    def __init__(self, max_length=256):\n",
        "        self.max_length = max_length\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/gemma/transformers/2b-it/2\")\n",
        "        self.gemma_lm = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/gemma/transformers/2b-it/2\")\n",
        "\n",
        "    def create_prompt(self, query, context):\n",
        "        # prompt template\n",
        "        prompt = f\"\"\"\n",
        "        You are an AI Agent specialized to answer to questions about Data Science.\n",
        "        Explain the concept or answer the question about Data Science.\n",
        "        In order to create the answer, please only use the information from the\n",
        "        context provided (Context). Do not include other information.\n",
        "        Answer with simple words.\n",
        "        If needed, include also explanations.\n",
        "        Question: {query}\n",
        "        Context: {context}\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def generate(self, query, retrieved_info):\n",
        "        prompt = self.create_prompt(query, retrieved_info)\n",
        "        input_ids = self.tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "        # Answer generation\n",
        "        answer = self.gemma_lm.generate(\n",
        "            input_ids,\n",
        "            #max_length=self.max_length, # limit the answer to max_length\n",
        "            max_new_tokens=self.max_length\n",
        "        )\n",
        "        # Decode and return the answer\n",
        "        answer = self.tokenizer.decode(answer[0], skip_special_tokens=True, skip_prompt=True)\n",
        "        return prompt, answer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T21:50:55.681148Z",
          "iopub.execute_input": "2024-04-05T21:50:55.681769Z",
          "iopub.status.idle": "2024-04-05T21:50:55.689575Z",
          "shell.execute_reply.started": "2024-04-05T21:50:55.681737Z",
          "shell.execute_reply": "2024-04-05T21:50:55.68867Z"
        },
        "trusted": true,
        "id": "-Zxjp4OpSI-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the AIAgent"
      ],
      "metadata": {
        "id": "kRGAEodFSI-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ai_agent = AIAgent()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T21:51:00.576937Z",
          "iopub.execute_input": "2024-04-05T21:51:00.577802Z",
          "iopub.status.idle": "2024-04-05T21:51:06.024217Z",
          "shell.execute_reply.started": "2024-04-05T21:51:00.577769Z",
          "shell.execute_reply": "2024-04-05T21:51:06.023455Z"
        },
        "trusted": true,
        "id": "T5IXR6FDSI-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the context from the Data Science interview Q&A treasury."
      ],
      "metadata": {
        "id": "trWZTS9xSI-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 1000)\n",
        "data_df = pd.read_csv(\"/kaggle/input/data-science-interview-q-and-a-treasury/dataset.csv\")\n",
        "data_df.head(3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T21:51:09.127058Z",
          "iopub.execute_input": "2024-04-05T21:51:09.127706Z",
          "iopub.status.idle": "2024-04-05T21:51:09.142835Z",
          "shell.execute_reply.started": "2024-04-05T21:51:09.127674Z",
          "shell.execute_reply": "2024-04-05T21:51:09.141983Z"
        },
        "trusted": true,
        "id": "hXuAgWxlSI-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = data_df.iloc[0].answer\n",
        "print(\"Context: \", context)\n",
        "prompt, answer = ai_agent.generate(query=\"What is supervised learning?\", retrieved_info=context)\n",
        "print(\"LLM Answer: \", answer)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T21:51:13.377434Z",
          "iopub.execute_input": "2024-04-05T21:51:13.37813Z",
          "iopub.status.idle": "2024-04-05T21:51:50.460568Z",
          "shell.execute_reply.started": "2024-04-05T21:51:13.3781Z",
          "shell.execute_reply": "2024-04-05T21:51:50.459664Z"
        },
        "trusted": true,
        "id": "5-cyzUprSI-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGSystem:\n",
        "    \"\"\"Sentence embedding based Retrieval Based Augmented generation.\n",
        "        Given database of pdf files, retriever finds num_retrieved_docs relevant documents\"\"\"\n",
        "    def __init__(self, ai_agent, num_retrieved_docs=2):\n",
        "        # load the data\n",
        "        self.num_docs = num_retrieved_docs\n",
        "        self.ai_agent = ai_agent\n",
        "        loader = CSVLoader(\"/kaggle/input/data-science-interview-q-and-a-treasury/dataset.csv\")\n",
        "        documents = loader.load()\n",
        "        self.template = \"\\n\\nQuestion:\\n{question}\\n\\nPrompt:\\n{prompt}\\n\\nAnswer:\\n{answer}\\n\\nContext:\\n{context}\"\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=800,\n",
        "            chunk_overlap=100)\n",
        "        all_splits = text_splitter.split_documents(documents)\n",
        "        # create a vectorstore database\n",
        "        embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "        self.vector_db = Chroma.from_documents(documents=all_splits,\n",
        "                                               embedding=embeddings,\n",
        "                                               persist_directory=\"chroma_db\")\n",
        "        self.retriever = self.vector_db.as_retriever()\n",
        "\n",
        "    def retrieve(self, query):\n",
        "        # retrieve top k similar documents to query\n",
        "        docs = self.retriever.get_relevant_documents(query)\n",
        "        return docs\n",
        "\n",
        "    def query(self, query):\n",
        "        # generate the answer\n",
        "        context = self.retrieve(query)\n",
        "        data = \"\"\n",
        "        for item in list(context):\n",
        "            data += item.page_content\n",
        "\n",
        "        data = data[:500]\n",
        "\n",
        "        prompt, answer = self.ai_agent.generate(query, data)\n",
        "\n",
        "        return self.template.format(question=query,\n",
        "                                    prompt=prompt,\n",
        "                                   answer=answer,\n",
        "                                   context=context)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T21:52:26.673255Z",
          "iopub.execute_input": "2024-04-05T21:52:26.674175Z",
          "iopub.status.idle": "2024-04-05T21:52:26.684815Z",
          "shell.execute_reply.started": "2024-04-05T21:52:26.674141Z",
          "shell.execute_reply": "2024-04-05T21:52:26.683831Z"
        },
        "trusted": true,
        "id": "1_j7dg8aSI-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def colorize_text(text):\n",
        "    for word, color in zip([\"Question\", \"Prompt\", \"Answer\", \"Context\"], [\"blue\", \"magenta\", \"red\", \"green\"]):\n",
        "        text = text.replace(f\"\\n\\n{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
        "    return text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T21:52:30.474444Z",
          "iopub.execute_input": "2024-04-05T21:52:30.474943Z",
          "iopub.status.idle": "2024-04-05T21:52:30.480137Z",
          "shell.execute_reply.started": "2024-04-05T21:52:30.474911Z",
          "shell.execute_reply": "2024-04-05T21:52:30.479119Z"
        },
        "trusted": true,
        "id": "rUxZd9wxSI-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the RAG system"
      ],
      "metadata": {
        "id": "UBP4La6HSI-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_system = RAGSystem(ai_agent)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T21:52:32.259229Z",
          "iopub.execute_input": "2024-04-05T21:52:32.260118Z",
          "iopub.status.idle": "2024-04-05T21:52:35.483929Z",
          "shell.execute_reply.started": "2024-04-05T21:52:32.260082Z",
          "shell.execute_reply": "2024-04-05T21:52:35.48293Z"
        },
        "trusted": true,
        "id": "xSW5KYH8SI-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try first with few of the questions from the data we used for the retrieval system."
      ],
      "metadata": {
        "id": "qlzE-QxhSI-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag_system.query(data_df.iloc[0].question)\n",
        "display(Markdown(colorize_text(answer)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T21:52:35.485642Z",
          "iopub.execute_input": "2024-04-05T21:52:35.485939Z",
          "iopub.status.idle": "2024-04-05T21:52:51.107428Z",
          "shell.execute_reply.started": "2024-04-05T21:52:35.485915Z",
          "shell.execute_reply": "2024-04-05T21:52:51.106434Z"
        },
        "trusted": true,
        "id": "AF3f7NPtSI-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag_system.query(data_df.iloc[3].question)\n",
        "display(Markdown(colorize_text(answer)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T21:52:51.109295Z",
          "iopub.execute_input": "2024-04-05T21:52:51.109581Z",
          "iopub.status.idle": "2024-04-05T21:53:32.336136Z",
          "shell.execute_reply.started": "2024-04-05T21:52:51.109557Z",
          "shell.execute_reply": "2024-04-05T21:53:32.335242Z"
        },
        "trusted": true,
        "id": "dkZ9t9iFSI-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag_system.query(\"What’s the normal distribution? Why do we care about it?\")\n",
        "display(Markdown(colorize_text(answer)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T21:53:32.337216Z",
          "iopub.execute_input": "2024-04-05T21:53:32.337526Z"
        },
        "trusted": true,
        "id": "CNap36zJSI-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try also with some \"fresh\" questions."
      ],
      "metadata": {
        "id": "yvSwNYZfSI-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag_system.query(\"Please explain bias and variance?\")\n",
        "display(Markdown(colorize_text(answer)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T20:28:37.108094Z",
          "iopub.execute_input": "2024-04-05T20:28:37.108685Z",
          "iopub.status.idle": "2024-04-05T20:29:59.558841Z",
          "shell.execute_reply.started": "2024-04-05T20:28:37.108649Z",
          "shell.execute_reply": "2024-04-05T20:29:59.557833Z"
        },
        "trusted": true,
        "id": "AOnBJhzjSI-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag_system.query(\"What is a Dropout?\")\n",
        "display(Markdown(colorize_text(answer)))"
      ],
      "metadata": {
        "trusted": true,
        "id": "03sdn2eBSI-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions\n",
        "\n",
        "We tested a RAG system developed with Gemma as LLM, Langchain for data loaders utilities, and ChromaDB as database.\n",
        "The RAG system is initialized with a dataset, that is used to populate the vector database, and with an AI Agent, that will query Gemma, given the initial query and the retrieved context.\n",
        "To verify that the result is composed based on the context provided, we include as well the context in the exported result.\n"
      ],
      "metadata": {
        "id": "q3stgkq2SI-1"
      }
    }
  ]
}